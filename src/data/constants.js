export const researchData = [
    {
        title: "Multi-modal Learning",
        description:
            "Deep learning with multiple modalities of data including images, videos, text and audio. Our team at IVAL explores how multi-modal understanding can be used for improving generalization in vision applications such as open-vocabulary object detection, and visual question-answering.",
    },
    {
        title: "Remote Sensing and Earth Vision",
        description:
            "Remote sensing data provide an unbiased, uninterrupted and borderless view of human activities and natural processes. Powered by data collected from diverse satellite systems, deep-learning models can be used to gain insight to guide targeted actions in remote locations.",
    },
    {
        title: "Person Centric Vision",
        description:
            "Under the theme of human-centric visual analysis using deep learning, our team at IVAL explores problems including face detection, facial landmark localization, pedestrian detection and abnormal activity detection.",
    },
    {
        title: "Synthesis and Generation",
        description:
            "Our team at IVAL researches new methods for generating high-resolution, realistic images and videos, and generation of synthetic data. Our team also works on fundamental concepts in generative models.",
    },
    {
        title: "Visual Recognition with Limited Supervision",
        description:
            "The theme explores various generic vision applications using deep learning with limited supervision including semi-supervised, weakly-supervised, few-shot, zero-shot, and self-supervised learning.",
    },
    {
        title: "Medical Image Analysis",
        description:
            "Our team at IVAL investigates real-world healthcare problems using medical imaging with deep learning and computer vision. We are also interested in investigating fundamental concepts in medical imaging such as multi-organ segmentation, medical image generation and deep-learning architectures for medical imaging.",
    },
];

export const cards = [
    {
        title: "Ten papers accepted in ICCV 2023.",
        description: "Ten (10) papers accepted from the IVAL group in the competitive IEEE/CVF...",
        link: "#",
        image: "https://placehold.co/300x200",
    },
    {
        title: "Introducing Oryx: An MBZUAI library for Large Vision-...",
        description: "Today, we are publicly releasing a set of projects and demos for a breed of large...",
        link: "#",
        image: "https://placehold.co/300x300",
    },
    {
        title: "Eleven papers accepted in CVPR 2023.",
        description: "Eleven (11) papers accepted from the IVAL group in the competitive IEEE/CVF...",
        link: "#",
        image: "https://placehold.co/300x150",
    },
    {
        title: "Six papers accepted in ECCV 2022.",
        description: "Six (6) papers accepted from the group in the competitive European Conference of...",
        link: "#",
        image: "https://placehold.co/300x180",
    },
    {
        title: "Three papers accepted in NeurIPS 2022.",
        description: "Three (3) papers accepted from the group in the competitive 36th Conferenc...",
        link: "#",
        image: "https://placehold.co/300x200",
    },
    {
        title: "Four (4) papers accepted in NeurIPS 2021 and ICLR 2021.",
        description: "Three (3) papers accepted from the group in the Neural Information Processing...",
        link: "#",
        image: "https://placehold.co/300x250",
    },
    {
        title: "Ten papers accepted in CVPR 2022.",
        description: "Ten (10) papers accepted from the group in the competitive IEEE/CVF Conference of...",
        link: "#",
        image: "https://placehold.co/300x200",
    },
    {
        title: "Five papers accepted in ICCV 2021.",
        description: "Five (5) papers accepted from the group in the competitive IFFF/CVF International...",
        link: "#",
        image: "https://placehold.co/300x100",
    },
];

export const newsItems = [
    { id: 1, text: "Ten papers accepted in ICCV 2023." },
    { id: 2, text: "Introducing Oryx: An MBZUAI library for Large Vision-..." },
    { id: 3, text: "Eleven papers accepted in CVPR 2023." },
];

export const highlights = [
    {
        title: "ACCV 2022 Workshop",
        subtitle: "Vision Transformers: Theory and Applications",
        description:
            "The first one-day conference on vision transformers, on the occasion of ACCV 2022, is an exciting chance to present and discuss vision transformers and their applications in various computer vision sub-fields. The workshop showcases exciting invited talks by Prof. Mubarak Shah, Ming-Hsuan Yang, and Rita Cucchiara.",
        link: "#"
    },
    {
        title: "NeurIPS 2023 Keynote",
        subtitle: "Advancements in AI",
        description:
            "Keynote session on AI advancements at NeurIPS 2023, covering vision models, deep learning, and generative AI applications.",
        link: "#"
    },
    {
        title: "ICLR 2023 Paper",
        subtitle: "Self-Supervised Learning",
        description:
            "Our latest paper on self-supervised learning for vision applications has been accepted at ICLR 2023.",
        link: "#"
    }
];


export const facultyMembers = [
    {
        name: "Dr. Alice Johnson",
        designation: "Professor, Computer Science",
        email: "alice.johnson@example.com",
        website: "https://alicejohnson.com",
        scholar: "https://scholar.google.com/citations?user=alice",
        image: "https://placehold.co/200x300"
    },
    {
        name: "Dr. Robert Smith",
        designation: "Associate Professor, AI Research",
        email: "robert.smith@example.com",
        website: "https://robertsmith.ai",
        scholar: "https://scholar.google.com/citations?user=robert",
        image: "https://placehold.co/200x300"
    },
    {
        name: "Dr. Emily Carter",
        designation: "Assistant Professor, Data Science",
        email: "emily.carter@example.com",
        website: "https://emilycarterds.com",
        scholar: "https://scholar.google.com/citations?user=emily",
        image: "https://placehold.co/200x300"
    },
    {
        name: "Dr. Emily Carter",
        designation: "Assistant Professor, Data Science",
        email: "emily.carter@example.com",
        website: "https://emilycarterds.com",
        scholar: "https://scholar.google.com/citations?user=emily",
        image: "https://placehold.co/200x300"
    },
    {
        name: "Dr. Emily Carter",
        designation: "Assistant Professor, Data Science",
        email: "emily.carter@example.com",
        website: "https://emilycarterds.com",
        scholar: "https://scholar.google.com/citations?user=emily",
        image: "https://placehold.co/200x300"
    },
];